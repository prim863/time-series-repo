---
title: "Time Series Project"
subtitle: "Exploring a Time Series with Meta's Prophet - MTH6139 Coursework 1"
author:
- name: Priyangaa Magindan
date: "March 2024"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri("QMlogo.png"), 
               alt = 'logo', 
               style = 'position:absolute; top:0; right:0; padding:10px; width:25%;')
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction
This is a data analytics project exploring a time series using ***Meta's Prophet*** forecasting system.
<center>
![](ProphetLogo.png)
</center>

### The Data
The dataset that we are going to explore in this project was found here:
<center>
<https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data>
</center>


The dataset consists of data about the climate in Delhi, India over a period of approximately 4 years and 4 months (collected from Weather Underground API). Specifically, it contains measurements of the mean temperature, humidity, wind speed and mean pressure in the city from 1st January 2013 to 24th April 2017. 

This data is split between two files: a training file (`DailyDelhiClimateTrain.csv`) and a testing file (`DailyDelhiClimateTest.csv`). The former contains the data for the full four years 2013-2016, and the latter has the data for the first 114 days of 2017.

We will focus on the training dataset now and use the testing dataset later on.

```{r}
FullDelhiClimateData_Train<-read.csv("DailyDelhiClimateTrain.csv") #Importing the data into R

#Brief exploration of the data
class(FullDelhiClimateData_Train)
dim(FullDelhiClimateData_Train) #Size of the data
head(FullDelhiClimateData_Train)
summary(FullDelhiClimateData_Train)
```

For simplicity, we will limit our exploration to a single variable in the dataset: mean temperature.
```{r}
MeanTemp.df<-FullDelhiClimateData_Train[c("date","meantemp")]
head(MeanTemp.df)
```

Theoretically, the same code written in this project can be altered to apply to any of the other 3 variables by changing which column of the full dataset we use.

### First Look at the Time Series
To begin, let us have a quick look at a simple plot of the mean temperature time series:
```{r}
MeanTemp_ts<-ts(MeanTemp.df$meantemp, frequency=365, start=c(2013,1))
plot(MeanTemp_ts)
```

We can already see a clear yearly seasonal component and, looking closely, there seems to be a slight positive trend over the 4 years.

### Trying a Simple Linear Regression
We can run a simple linear model to see the growth of the time series:
```{r}
LinearModel=lm(MeanTemp_ts~time(MeanTemp_ts),na.action=NULL)
plot(MeanTemp_ts,type="l")
lines(fitted(LinearModel),col="red")
```

Clearly, this is not the best regression model to run on this data, but it does show us the slight trend in the data.

### Decomposing the Time Series
We can use the `decompose()` function in R to get a quick look at the underlying patterns of the components in the time series:
```{r}
TSDecomposition<-decompose(MeanTemp_ts)
plot(TSDecomposition)
```

## Meta's Prophet Forecasting Tool
Now that we have a base understanding of the time series we are exploring and its components, we move on to using Prophet.

### Introducing Prophet
In short, Prophet is a procedure developed by Meta (formerly Facebook) for forecasting time series data.

For more information, see here: <https://facebook.github.io/prophet/> and here: <https://research.facebook.com/blog/2017/02/prophet-forecasting-at-scale/>

To use Prophet in R, our dataframe needs to have the following columns: `ds` (date type) and `y` (the time series).
```{r}
colnames(MeanTemp.df)<-c("ds","y")
head(MeanTemp.df)
```

For this project, we will use the default version of Prophet that is installed with `install.packages("prophet")`.

### Using Prophet
Now that the dataframe is prepared, we can create our Prophet model:
```{r}
ProphetModel=prophet::prophet(MeanTemp.df)
```

Next, we make a dataframe with future dates for forecasting:
```{r}
Future=prophet::make_future_dataframe(ProphetModel, periods=365, freq="day")
```

Finally, we create and plot our time series forecast:
```{r}
Forecast=predict(ProphetModel,Future)
plot(ProphetModel,Forecast,xlabel="Time",ylabel="MeanTemperature")
```

The black points represent the real data from the dataset we have and the dark blue points represent the Prophet model's predicted `y` values, with the light blue section showing the upper and lower bounds.

Here is an interactive version of the above plot for closer exploration (use the range selector at the bottom to zoom in on specific time periods):
```{r}
prophet::dyplot.prophet(ProphetModel,Forecast)
```

We can also look at the individual components present in our model:
```{r}
prophet::prophet_plot_components(ProphetModel,Forecast)
```

These plots show us the values of each component that are added to the stationary `y` values to create the final forecast.

They seem to support our previous inferences of trend and seasonality in the data whilst providing more detail.

We can see that the trend added is mostly positive but looks to be varied (not constant). 2013 barely has any trend added. Starting around mid-2014 there looks to be a negative value representing the trend for about a year. From mid-2015 onward, we see an increasingly positive value representing trend (which becomes slightly less increasing from early 2016).

We can also see that there seems to be some weekly seasonality in addition to the yearly seasonality we inferred earlier. Monday to Friday have non-negative values added to represent weekly seasonality whilst the weekend days have negative values. Looking at yearly seasonality, the summer months have positive values added to represent yearly seasonality, whilst winter months have negative values. This looks to follow a fairly intuitive pattern given the seasons throughout the year and the effect that they would have had on temperature.

## Evaluating the Forecast
Given that the original dataset source has a separate testing file, we can use that to test the Prophet forecast.

### 2017 Data
Here we create a dataframe with the real values that we have for early 2017 and add columns for the predicted values and bounds from our Prophet model:
```{r}
RealVsPredicted<-read.csv("DailyDelhiClimateTest.csv") #Import the real data
RealVsPredicted<-RealVsPredicted[c("date","meantemp")] #Only looking at Mean Temperature

#Since we only have real data for the first 114 days of 2017, we only add the corresponding values from the set of predicted values and bounds from the Prophet `y` values.
RealVsPredicted$prophetpredictions<-Forecast$yhat[1462:1575]
RealVsPredicted$prophetpredictions_upper<-Forecast$yhat_upper[1462:1575]
RealVsPredicted$prophetpredictions_lower<-Forecast$yhat_lower[1462:1575]
```

### Visual Comparison
Here is a basic plot to see the real vs. predicted values for early 2017:
```{r}
plot(ts(RealVsPredicted$meantemp,frequency=365,start=c(2017,1)),ylab="Temperature",main="01/01/2017 to 24/04/2017 Temperatures",ylim=c(10,40))
lines(ts(RealVsPredicted$prophetpredictions,frequency=365,start=c(2017,1)),col="blue")
lines(ts(RealVsPredicted$prophetpredictions_upper,frequency=365,start=c(2017,1)),col="cyan")
lines(ts(RealVsPredicted$prophetpredictions_lower,frequency=365,start=c(2017,1)),col="cyan")
legend("topleft",legend=c("Real","Predicted","PredictedBounds"),fill=c("black","blue","cyan"))
```

Here is an interactive version:
```{r}
Comparison<-dygraphs::dygraph(xts::xts(RealVsPredicted,as.Date(RealVsPredicted$date)),ylab="Temperature",main="01/01/2017 to 24/04/2017 Temperatures")
dygraphs::dyLegend(Comparison, width=550)
```

### Metrics for Evaluating
Here we calculate some metrics that can be used to evaluate the Prophet model:

Mean Squared Error
```{r}
mean((RealVsPredicted$meantemp-RealVsPredicted$prophetpredictions)^2) #MSE
```

Root Mean Squared Error
```{r}
sqrt(mean((RealVsPredicted$meantemp-RealVsPredicted$prophetpredictions)^2)) #RMSE
```

Mean Absolute Error
```{r}
mean(abs(RealVsPredicted$meantemp-RealVsPredicted$prophetpredictions)) #MAE
```

Mean Absolute Percentage Error
```{r}
mean(abs(RealVsPredicted$meantemp-RealVsPredicted$prophetpredictions)/RealVsPredicted$meantemp)*100 #MAPE
```

There is no exact threshold to decide if these values tell us that the model is good or not. In general, the lower that these values are, the better the regression model.

<center>
**End of Project**
</center>